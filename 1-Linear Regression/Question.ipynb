{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1: Linear Regression with One Variable\n",
    "\n",
    "### Objective\n",
    "Implement linear regression with one variable to predict profits for a food truck based on the population of a city.\n",
    "\n",
    "### Theory\n",
    "The linear regression model:\n",
    "\n",
    "$h_\\theta(x) = \\theta^T x = \\theta_0 + \\theta_1 x$\n",
    "\n",
    "The cost function to minimize:\n",
    "\n",
    "$J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$\n",
    "\n",
    "The gradient descent update rule: \n",
    "\n",
    "$\\theta_j := \\theta_j - \\alpha \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}$\n",
    "\n",
    "### Data \n",
    "The data is in `ex1data1.txt` with two columns: population of a city (x) and profit of a food truck (y). \n",
    "\n",
    "### Functions\n",
    "- `plotData` - Plots the training data \n",
    "- `computeCost` - Computes the cost function $J(\\theta)$\n",
    "- `gradientDescent` - Performs gradient descent to learn $\\theta$\n",
    "- `predict` - Makes predictions on new data using the learned $\\theta$ parameters\n",
    "\n",
    "### Steps\n",
    "1. Plot data \n",
    "2. Compute cost for initial $\\theta$\n",
    "3. Perform gradient descent to minimize $J(\\theta)$ \n",
    "4. Make predictions on new data\n",
    "\n",
    "## Exercise 2: Linear Regression with Multiple Variables (Optional)\n",
    "\n",
    "### Objective \n",
    "Implement linear regression with multiple variables to predict housing prices.\n",
    "\n",
    "### Theory\n",
    "Same as Exercise 1 but with multiple features.\n",
    "\n",
    "### Data\n",
    "The data is in `ex1data2.txt` with size of house (x1), number of bedrooms (x2) and house price (y).\n",
    "\n",
    "### Additional Functions\n",
    "- `featureNormalize` - Normalizes features \n",
    "- `computeCostMulti` - Cost function for multiple variables\n",
    "- `gradientDescentMulti` - Gradient descent for multiple variables  \n",
    "- `normalEqn` - Calculates closed-form solution for $\\theta$\n",
    "\n",
    "### Steps\n",
    "Same 4 steps as Exercise 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
